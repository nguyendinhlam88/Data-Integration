# Data-Integration

B1: Chạy file yml bằng docker-compose filename.yml up từ kafka và spark
B2: Tạo ra các spider tương ứng với các nguồn mình crawl
B3: Định nghĩa các item và pipeline tương ứng và tạo topic theo từng nguồn, đẩy lên kafka
B4: Xem file test để hiểu hơn cách kết nối và đẩy dữ liệu